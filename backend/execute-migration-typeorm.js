const { DataSource } = require('typeorm');
const fs = require('fs');
const path = require('path');

async function executeMigration() {
    console.log('ðŸ”§ Iniciando migraÃ§Ã£o via TypeORM...');
    
    // ConfiguraÃ§Ã£o do banco (mesma do projeto)
    const dataSource = new DataSource({
        type: 'postgres',
        host: process.env.DB_HOST || 'localhost',
        port: parseInt(process.env.DB_PORT) || 5432,
        username: process.env.DB_USERNAME || 'admin',
        password: process.env.DB_PASSWORD || 'password',
        database: process.env.DB_DATABASE || 'kmiza27_db',
        synchronize: false,
        logging: true,
    });

    try {
        // Conectar
        await dataSource.initialize();
        console.log('âœ… Conectado ao banco de dados');

        // Ler o arquivo SQL
        const sqlPath = path.join(__dirname, 'database', 'migrations', 'fix-pools-conflict.sql');
        const sqlContent = fs.readFileSync(sqlPath, 'utf8');
        
        console.log('ðŸ“ Executando migraÃ§Ã£o SQL...');
        
        // Dividir o SQL em comandos individuais e executar
        const commands = sqlContent
            .split(';')
            .map(cmd => cmd.trim())
            .filter(cmd => cmd.length > 0 && !cmd.startsWith('--'));
        
        for (let i = 0; i < commands.length; i++) {
            const command = commands[i];
            if (command && command.trim()) {
                try {
                    console.log(`âš¡ Executando comando ${i + 1}/${commands.length}`);
                    await dataSource.query(command);
                } catch (error) {
                    if (error.message.includes('nÃ£o existe') || error.message.includes('does not exist')) {
                        console.log(`âš ï¸ Comando ${i + 1} - Objeto jÃ¡ foi removido (OK): ${error.message}`);
                    } else {
                        console.error(`âŒ Erro no comando ${i + 1}:`, error.message);
                        // Continuar mesmo com erro para tentar executar o resto
                    }
                }
            }
        }
        
        console.log('âœ… MigraÃ§Ã£o concluÃ­da!');
        
        // Verificar se as tabelas foram criadas
        console.log('ðŸ” Verificando tabelas criadas...');
        const tables = await dataSource.query(`
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public' 
                AND table_name LIKE 'pool%'
            ORDER BY table_name
        `);
        
        console.log('ðŸ“Š Tabelas encontradas:', tables.map(t => t.table_name));
        
        // Verificar estrutura da tabela pools
        console.log('ðŸ” Verificando estrutura da tabela pools...');
        const columns = await dataSource.query(`
            SELECT column_name, data_type, is_nullable
            FROM information_schema.columns 
            WHERE table_schema = 'public' 
                AND table_name = 'pools'
            ORDER BY ordinal_position
        `);
        
        console.log('ðŸ“‹ Colunas da tabela pools:');
        columns.forEach(col => {
            console.log(`  - ${col.column_name}: ${col.data_type} ${col.is_nullable === 'YES' ? '(nullable)' : '(not null)'}`);
        });
        
    } catch (error) {
        console.error('âŒ Erro durante migraÃ§Ã£o:', error.message);
        throw error;
    } finally {
        if (dataSource.isInitialized) {
            await dataSource.destroy();
            console.log('ðŸ”Œ ConexÃ£o fechada');
        }
    }
}

// Executar migraÃ§Ã£o
executeMigration()
    .then(() => {
        console.log('ðŸŽ‰ MigraÃ§Ã£o finalizada com sucesso!');
        process.exit(0);
    })
    .catch(error => {
        console.error('ðŸ’¥ Falha na migraÃ§Ã£o:', error);
        process.exit(1);
    });